---
mathjax: true
id: 7537
title: "Virtual AMA with Sam Altman by Harry Stebbings - DevDay 2024"
date: 2024-12-19
permalink: /booksummary/Virtual-AMA-with-SamAltma-by-Harry-Stebbings-DevDay2024
tags:
  - "OpenAI"
  - "AI"
  - "Founder"
  - "DevDay2024"
  - "Harry Stebbings"
  - "Sam Altman"
categories:
header:
  teaser: /assets/images/default/summary.jpg
author: Hari Thapliyaal
layout: booksum-layout
excerpt: "A summary of the key points discussed between Sam Altman, CEO of OpenAI, and Harry Stebbings, on DevDay2024. The chat includes a wide range of topics such as the future of AI, OpenAI's strategies, and how founders and investors should think about AI. "
author_profile: true
share: true
toc: false
toc_sticky: true
toc_levels: 3
comments: true
keywords: [OpenAI, AI, Founder, DevDay2024, Harry Stebbings, Sam Altman, Entrepreneur, Innovator, Business Leader]
---

![Virtual AMA with Sam Altman](/assets/images/default/summary.jpg)

Sometimes, it's more important to know what questions can be asked than to have the answers. So, take a moment to pause and think about how you would respond if you were in Sam Altman's position.

Leaders aren't born; they are shaped by their struggles, opportunities, and attitudes towards them. Regardless of whether you watch this interview or not, take 10 minutes to read or listen to these questions out loud to yourself. They will help you shape your thought process.

While reading these make a note that many of these questions were triggered from the answer of Sam Altman, so it is not possible to draft these kinds of questions in advance. To answer these questions you need to be deep inside the business of AI and you need to understand OpenAI's vision, strategy, competition etc. Which is a unique position and no other person can think like Sam thinks because of your his position, role, exposure, and knowledge.  

Whether it's a political interview, job interview, business interview, or brand interview, an interviewee needs to face all kinds of questions. In fact, you shine only when you go through the tough questions. We need to learn how to deflect the uneasy questions, sometimes pause and think, sometimes use humor or body language to dilute the question.

Best of luck as you embark on this journey of asking yourself questions without answers.

1. When we look forward, is the future of OpenAI more models like o1, or is it more larger models like old?
1. How do you think about developing no-code tools for non-technical founders to build and scale AI apps?
1. How far up the stack is OpenAI going to go? Is it a waste of time for founders to spend time tuning their RAG system because OpenAI thinks they'll own this part of the application layer? 
1. How should founders and investors think about areas where OpenAI might "steamroll" versus areas where OpenAI might not?
1. How did you think about Masa's statement regarding $9 trillion of value creation every year offsetting $9 trillion of capex?
1. How do you think about the role of open-source in the future of AI?
1. How do you define agents, and what is an agent to you?
1. What do people think about agents that they get wrong?
1. Does this fundamentally change the way that SaaS is priced, particularly when replacing labor?
1. Do we need to build specific models for agentic use or do we not?
1. How do you respond to the idea that models are depreciating assets?
1. How does OpenAI plan to continue differentiating its models over time?
1. How do you think about reasoning and multimodality specifically?
1. How will vision capabilities scale with new inference-time paradigms set by o1?
1. How do you think about internationalization with models, especially for different cultures and languages?
1. How does OpenAI make breakthroughs in core reasoning, and do we need to push into reinforcement learning or other techniques?
1. How has OpenAI maintained morale during long and winding research paths or failed training runs?
1. What unmade decision weighs on your mind the most?
1. How do you think about semiconductor supply chains and international tensions today?
1. What's your top worry about the complexity of the AI ecosystem?
1. Do you agree with Larry Ellison's statement that it will cost $100 billion to enter the foundation model race?
1. If you were building today as a 23- or 24-year-old, what would you choose to build?
1. If you were to write a book, what would you call it?
1. What in AI does no one focus on that everyone should spend more time on?
1. What was one thing that surprised you in the last month?
1. Which competitor do you most respect and why?
1. How do you think about the trade-off between latency and accuracy?
1. What area of your leadership would you most like to improve?
1. What makes Kevin (head of product) world-class as a product leader to you?
1. What question are you not often or never asked that you wish you were asked?
1. Can you paint the scenario for OpenAI in five years and ten years?
1. How should developers think about when to pick OpenAI versus a different provider, like Anthropic, whose models are sometimes cited as better for coding?
1. How many more model iterations do you think scaling laws will hold true for?
1. Have you ever doubted that the trajectory of model capability improvement will continue? Why?
1. What was the hardest paradigm shift or training run issue to navigate, and how did you get through it?
1. Is it difficult to maintain morale when facing long and winding research challenges or failed training runs?
1. How do you maintain morale when things don't go as planned in research or development?
1. What unmade decision weighs on your mind the most, and why?
1. Is there a commonality in the person you consult when facing 51/49 decisions?
1. How worried are you about semiconductor supply chains and international tensions today?
1. What is your top worry related to the AI field or OpenAI specifically?
1. Do you agree with people comparing the AI wave to the internet bubble or other technological revolutions?
1. If someone said building AI itself requires $10 billion or $100 billion, do you think that’s accurate?
1. What analogies for AI do you find most or least appropriate (e.g., internet, electricity, transistor)?
1. If you were building a product today, what would you choose to create, and why?
1. What’s your favorite OpenAI API and why?
1. What are the biggest constraints on models like Llama from being open source?
1. Who do you most respect in AI today?
1. What insecurities in leadership do you have, and where do you most want to improve as a leader?
1. What did you not know when starting OpenAI that you would have liked more time to learn?
1. How do you balance short-term product goals with long-term strategy in a rapidly evolving field?
1. How do you keep OpenAI focused on 10x growth rather than 10% growth in a high-speed environment?
1. If you had a magic wand to shape OpenAI’s future five and ten years from now, what would that look like?

[Virtual AMA with Sam Altman, moderated by Harry Stebbings - DevDay 2024](https://www.youtube.com/watch?v=Hn27upT2m_o)