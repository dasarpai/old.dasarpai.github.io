{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langid\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB 131.3 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.0/1.9 MB 196.9 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.1/1.9 MB 302.7 kB/s eta 0:00:07\n",
      "     -------- ------------------------------- 0.4/1.9 MB 1.3 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 1.0/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.2/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.4/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.6/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.8/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.9/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.9/1.9 MB 2.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages (from langid) (1.25.2)\n",
      "Building wheels for collected packages: langid\n",
      "  Building wheel for langid (setup.py): started\n",
      "  Building wheel for langid (setup.py): finished with status 'done'\n",
      "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941179 sha256=3fc8e4fc9bd01f43b4648ca6538282743db38195ba4a4de830d240533be00772\n",
      "  Stored in directory: c:\\users\\hari_\\appdata\\local\\pip\\cache\\wheels\\93\\95\\a9\\c292c9dd8cadb8f2359f1670ff198a40d47167b0be3236e1c8\n",
      "Successfully built langid\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "\n",
    "def identify_language(word):\n",
    "    lang, confidence = langid.classify(word)\n",
    "    return lang, confidence\n",
    "\n",
    "def separate_sanskrit_words(word_list, confidence_threshold=0.9):\n",
    "    sanskrit_words = []\n",
    "    # print(word_list)\n",
    "    for word in word_list:\n",
    "        lang, confidence = identify_language(word)\n",
    "        print(word,lang,confidence)\n",
    "\n",
    "        if not (lang == 'en' and confidence >= confidence_threshold):\n",
    "            sanskrit_words.append(word)\n",
    "\n",
    "    return sanskrit_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"abandon\", \"abandoned\", \"abandoner\", \"abandonest\", \"abandoneth\", \"abandoning\", \"abandoning-all\", \"abandonment\", \"abandons\", \"abashed\", \"abashment\", \"abate\", \"abated\", \"abatement\", \"abating\", \"abdicating\", \"abdomen\", \"abdominal\", \"abduct\", \"abducted\", \"abducting\", \"abduction\", \"abductor\", \"abducts\", \"abegging\", \"aberration\", \"abhasita\", \"abhasuras\", \"abhava\", \"abhaya\", \"abhibhu\", \"abhighatas\", \"abhijit\", \"abhimana\", \"abhimanyu\", \"abhimanyu-badha\", \"abhimanyu-uttara\", \"abhiras\", \"abhiru\", \"abhisaras\", \"abhisars\", \"abhishahas\", \"abhishava\", \"abhisheka\", \"abhorrence\", \"abhorrent\", \"abide\", \"abided\", \"abides\", \"abidest\", \"abideth\", \"abiding\", \"abikshit\", \"abilities\", \"ability\", \"abject\", \"abjectness\", \"ablaze\", \"able\", \"able-bodied\", \"abler\", \"ablution\", \"ablutions\", \"ably\", \"abnormal\", \"abode\", \"abodes\", \"abolished\", \"abolition\", \"abominable\", \"abomination\", \"abondoning\", \"abortion\", \"abortive\", \"abound\", \"abounded\", \"aboundeth\", \"abounding\", \"abounds\", \"about\", \"above\", \"above-mentioned\", \"abridge\", \"abridged\", \"abridgement\", \"abridgment\", \"abroad\", \"absence\", \"absent\", \"absent-minded\", \"absented\", \"absolute\", \"absolutely\", \"absolution\", \"absolve\", \"absolved\", \"absolveth\", \"absorb\", \"absorbed\", \"absorber\", \"absorbest\", \"absorbeth\", \"absorbing\", \"absorbs\", \"absorption\", \"abstain\", \"abstained\", \"abstainer\", \"abstainest\", \"abstaineth\", \"abstaining\", \"abstains\", \"abstemious\", \"abstemiously\", \"abstemiousness\", \"abstension\", \"abstention\", \"abstentions\", \"abstinence\", \"abstinences\", \"abstinent\", \"abstract\", \"abstracted\", \"abstraction\", \"abstracts\", \"abstruse\", \"absurd\", \"absurdity\", \"abuddha\", \"abundance\", \"abundant\", \"abundantly\", \"abuse\", \"abused\", \"abuser\", \"abuses\", \"abusive\", \"abut\", \"abutting\", \"abyakta\", \"abyss\", \"ac-quires\", \"acala\", \"accede\", \"acceded\", \"acceding\", \"accent\", \"accents\", \"accept\", \"acceptable\", \"acceptance\", \"accepted\", \"acceptest\", \"accepteth\", \"accepting\", \"acceptor\", \"acceptress\", \"accepts\", \"access\", \"accessible\", \"accession\", \"accessions\", \"accident\", \"accidental\", \"accidentally\", \"accidents\", \"acclamations\", \"accommodation\", \"accompanied\", \"accompanies\", \"accompaniment\", \"accompaniments\", \"accompany\", \"accompanying\", \"accomplish\", \"accomplished\", \"accomplisher\", \"accomplishes\", \"accomplishest\", \"accomplisheth\", \"accomplishing\", \"accomplishment\", \"accomplishments\", \"accord\", \"accord-one\", \"accordance\", \"accorded\", \"accordeth\", \"according\", \"accordingly\", \"accords\", \"accost\", \"accosted\", \"accosting\", \"account\", \"accountants\", \"accounted\", \"accountred\", \"accounts\", \"accoutred\", \"accoutrements\", \"accretion\", \"accrue\", \"accrued\", \"accrues\", \"accumulate\", \"accumulated\", \"accumulates\", \"accumulating\", \"accumulation\", \"accumulations\", \"accuracy\", \"accurate\", \"accurately\", \"accursed\", \"accusation\", \"accusations\", \"accuse\", \"accused\", \"accustomed\", \"ach\", \"achala\", \"achamana\", \"acharya\", \"acharyas\", \"ache\", \"aches\", \"acheth\", \"achievable\", \"achieve\", \"achieved\", \"achievement\", \"achievements\", \"achievements\", \"achiever\", \"achievers\", \"achieves\", \"achievest\", \"achieveth\", \"achieving\", \"aching\", \"achutasthala\", \"achyuta\", \"achyutayus\", \"acid\", \"acknowledge\", \"acknowledged\", \"acknowledging\", \"acknowledgment\", \"acme\", \"acoutred\", \"acquaint\", \"acquaintance\", \"acquainted\", \"acquatic\", \"acquiesced\", \"acquiescence\", \"acquiescing\", \"acquirable\", \"acquire\", \"acquired\", \"acquirement\", \"acquirements\", \"acquirer\", \"acquirers\", \"acquires\", \"acquireth\", \"acquiring\", \"acquisition\", \"acquisitions\", \"acquittance\", \"acquitted\", \"acquitting\", \"acrid\", \"acrimonious\", \"across\", \"act\", \"act-this\", \"acted\", \"actest\", \"acteth\", \"acting\", \"acting-chaitanya\", \"action\", \"actions\", \"active\", \"actively\", \"activity\", \"actor\", \"actors\", \"actress\", \"acts\", \"actual\", \"actually\", \"actuated\", \"acute\", \"acutely\", \"acutest\", \"acyuta\", \"acyutasthala\", \"acyutayudha\", \"ad\", \"adamant\", \"adamantine\", \"adambaras\", \"adamvara\", \"adaptability\", \"adapted\", \"adapting\", \"adbhuta\", \"add\", \"added\", \"adders\", \"addeth\", \"addict\", \"addicted\", \"addiction\", \"adding\", \"addition\", \"additional\", \"address\", \"addressed\", \"addresses\", \"addressest\", \"addresseth\", \"addressing\", \"addresst\", \"addrest\", \"adds\", \"adept\", \"adepts\", \"adequate\", \"adequately\", \"adhakshaja\", \"adharma\", \"adharyu\", \"adhere\", \"adhered\", \"adherence\", \"adherent\", \"adherents\", \"adheres\", \"adherest\", \"adhereth\", \"adhering\", \"adhesion\", \"adhi-daivata\", \"adhi-loka\", \"adhi-purusha\", \"adhi-vijnanam\", \"adhi-yajna\", \"adhibhuta\", \"adhidaiva\", \"adhidaivata\", \"adhiraja\", \"adhiratha\", \"adhirjayas\", \"adhishthana\", \"adhitratha\", \"adhivanga\", \"adhivasha\", \"adhiyajna\", \"adhokshaja\", \"adhrishya\", \"adhvaryus\", \"adhwaryu\", \"adhwaryyu\", \"adhyaryu\", \"adhyatma\", \"adhyudha\", \"adi\", \"adideva\", \"adieu\", \"adieus\", \"adipose\", \"aditi\", \"aditisuta\", \"aditya\", \"adityaketu\", \"adityas\", \"adivansavatara\", \"adivansavatarana\", \"adjacence\", \"adjacent\", \"adjective\", \"adjectives\", \"adjoining\", \"adjudicating\", \"adjuncts\", \"adjured\", \"adjusting\", \"administer\", \"administered\", \"administerer\", \"administereth\", \"administering\", \"administration\", \"administrative\", \"admiration\", \"admire\", \"admired\", \"admirers\", \"admission\", \"admit\", \"admits\", \"admittance\", \"admitted\", \"admittedly\", \"admittest\", \"admitting\", \"admixture\", \"admonish\", \"admonished\", \"admonition\", \"admonitions\", \"ado\", \"adopt\", \"adopted\", \"adopter\", \"adoptest\", \"adopteth\", \"adopting\", \"adoption\", \"adoptive\", \"adopts\", \"adorable\", \"adorableness\", \"adoration\", \"adorations\", \"adore\", \"adored\", \"adorer\", \"adorers\", \"adores\", \"adorest\", \"adoreth\", \"adoring\", \"adorn\", \"adorned\", \"adorning\", \"adornment\", \"adornments\", \"adorns\", \"adown\", \"adri\", \"adrift\", \"adrika\", \"adrisyanti\", \"adroit\", \"adroitly\", \"adulation\", \"adulatory\", \"adulterer\", \"adulterous\", \"adultery\", \"adults\", \"advance\", \"advance-divisions\", \"advanced\", \"advancement\", \"advancer\", \"advances\", \"advanceth\", \"advancing\", \"advancings\", \"advanta\", \"advantage\", \"advantageous\", \"advantages\", \"advent\", \"adventitious\", \"adventures\", \"adversaries\", \"adversary\", \"adverse\", \"adversity\", \"adverted\", \"adverting\", \"advice\", \"advisable\", \"advise\", \"advised\", \"advisedly\", \"adviser\", \"advisers\", \"advisest\", \"adviseth\", \"advisible\", \"advising\", \"advocates\", \"aerial\", \"affair\", \"affairs\", \"affect\", \"affected\", \"affecting\", \"affection\", \"affectionate\", \"affectionately\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# word_list = [\"mohan\", \"sanskrit\", \"another\", \"gayatri\"]\n",
    "sanskrit_words = separate_sanskrit_words(word_list, confidence_threshold=.3)\n",
    "\n",
    "print(sanskrit_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyICU\n",
      "  Downloading PyICU-2.12.tar.gz (260 kB)\n",
      "     ---------------------------------------- 0.0/260.0 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/260.0 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/260.0 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 30.7/260.0 kB 262.6 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 61.4/260.0 kB 328.2 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 174.1/260.0 kB 807.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 260.0/260.0 kB 1.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [58 lines of output]\n",
      "      (running 'icu-config --version')\n",
      "      (running 'pkg-config --modversion icu-i18n')\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 89, in <module>\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\os.py\", line 679, in __getitem__\n",
      "          raise KeyError(key) from None\n",
      "      KeyError: 'ICU_VERSION'\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 92, in <module>\n",
      "        File \"<string>\", line 19, in check_output\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 424, in check_output\n",
      "          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 505, in run\n",
      "          with Popen(*popenargs, **kwargs) as process:\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 951, in __init__\n",
      "          self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 1436, in _execute_child\n",
      "          hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "      FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 96, in <module>\n",
      "        File \"<string>\", line 19, in check_output\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 424, in check_output\n",
      "          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 505, in run\n",
      "          with Popen(*popenargs, **kwargs) as process:\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 951, in __init__\n",
      "          self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\subprocess.py\", line 1436, in _execute_child\n",
      "          hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "      FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "        File \"C:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "        File \"C:\\Users\\hari_\\AppData\\Local\\Temp\\pip-build-env-_q4e6zik\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "        File \"C:\\Users\\hari_\\AppData\\Local\\Temp\\pip-build-env-_q4e6zik\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\hari_\\AppData\\Local\\Temp\\pip-build-env-_q4e6zik\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 99, in <module>\n",
      "      RuntimeError:\n",
      "      Please install pkg-config on your system or set the ICU_VERSION environment\n",
      "      variable to the version of ICU you have installed.\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install PyICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polyglot\n",
      "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
      "     ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/126.3 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/126.3 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 30.7/126.3 kB 187.9 kB/s eta 0:00:01\n",
      "     -------------------- ---------------- 71.7/126.3 kB 302.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 126.3/126.3 kB 464.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: polyglot\n",
      "  Building wheel for polyglot (setup.py): started\n",
      "  Building wheel for polyglot (setup.py): finished with status 'done'\n",
      "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52603 sha256=3de4ddad7736b969d484896bac9e99bd7ae12cf90046aa44cc6416d8ce99f7a7\n",
      "  Stored in directory: c:\\users\\hari_\\appdata\\local\\pip\\cache\\wheels\\77\\4a\\9d\\5141018da475375d91dc1af07520b1f2b077579f2f55353afb\n",
      "Successfully built polyglot\n",
      "Installing collected packages: polyglot\n",
      "Successfully installed polyglot-16.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'icu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Text\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_sanskrit_word\u001b[39m(word):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Use polyglot to detect the language of the word\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m Text(word)\n",
      "File \u001b[1;32mc:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\polyglot\\text.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence, TextFile, TextFiles\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Detector, Language\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Downloader\n",
      "File \u001b[1;32mc:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\polyglot\\detect\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Detector, Language\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\polyglot\\detect\\base.py:11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Detecting languages\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01micu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Locale\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycld2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcld2\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'icu'"
     ]
    }
   ],
   "source": [
    "from polyglot.text import Text\n",
    "\n",
    "def is_sanskrit_word(word):\n",
    "    # Use polyglot to detect the language of the word\n",
    "    text = Text(word)\n",
    "    languages = [lang.code for lang in text.languages]\n",
    "    \n",
    "    # Check if Sanskrit is detected\n",
    "    return 'sa' in languages\n",
    "\n",
    "def separate_sanskrit_words(word_list):\n",
    "    sanskrit_words = [word for word in word_list if is_sanskrit_word(word)]\n",
    "    return sanskrit_words\n",
    "\n",
    "# Example usage:\n",
    "# word_list = [\"example\", \"sanskrit\", \"another\", \"abandonest\", \"संस्कृत\"]\n",
    "sanskrit_words = separate_sanskrit_words(word_list)\n",
    "\n",
    "print(sanskrit_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\hari_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gayatri is not identified as a Sanskrit word.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import indian\n",
    "\n",
    "# Download the Indian language corpora (including Sanskrit)\n",
    "nltk.download('indian')\n",
    "\n",
    "# Function to check if a word is likely Sanskrit\n",
    "def is_sanskrit_word(word):\n",
    "    sanskrit_words = set(indian.words())\n",
    "    return word.lower() in sanskrit_words\n",
    "\n",
    "# Example usage\n",
    "word = \"gayatri\"\n",
    "if is_sanskrit_word(word):\n",
    "    print(f\"{word} is likely a Sanskrit word.\")\n",
    "else:\n",
    "    print(f\"{word} is not identified as a Sanskrit word.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hari'] 1.0\n",
      "hari is not identified as a Sanskrit word.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def is_sanskrit_word(word):\n",
    "    # Load the English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Tokenize the word using Spacy\n",
    "    tokens = nlp(word)\n",
    "\n",
    "    # Check if more than half of the tokens are not recognized as English\n",
    "    english_tokens = [token.text.lower() for token in tokens if token.lang_ == \"en\"]\n",
    "    print(english_tokens, len(english_tokens) / len(tokens))\n",
    "    return len(english_tokens) / len(tokens) < 0.5\n",
    "\n",
    "# Example usage\n",
    "word = \"hari\"\n",
    "if is_sanskrit_word(word):\n",
    "    print(f\"{word} is likely a Sanskrit word.\")\n",
    "else:\n",
    "    print(f\"{word} is not identified as a Sanskrit word.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
