--- 
id: 6025       
title: "Statistics Interview Question for Data Scientist"   
date: '2023-01-06T15:50:00+05:30'   
permalink: /dsblog/Statistics-Interview-Question-for-Data-Scientist
categories:   
   
tags: [Statistics, Maths, Stats for Data Science]   
   
header:   
  teaser: "/assets/images/dspost/dsp6025-Statistics-Interview-Question-for-Data-Scientist.jpg"   
excerpt_separator: "<!--more-->"   
excerpt:   
layout: single   
author_profile: true   
toc: true   
toc_sticky: true
--- 

   
![Statistics Interview Question for Data Scientist](/assets/images/dspost/dsp6025-Statistics-Interview-Question-for-Data-Scientist.jpg)

# Statistics Interview Question for Data Scientist

> In this question-answer article, I will try that the answer of every question starts with example rather than theory (some unavoidable variation may be possible). I firmly believe if examples are clear, human mind is smart enough in generlization and creating theories.

# What is the difference between Measure, Tool, Technique, Method, Process?
- A measure is a way to calculate. It is a metric. For example mean, median, mode are measures to know the central tendency of data.
- A tool is a physical object or software or app used to accomplish a task. For example, microsoft project for creating project scheule and identifying critical path.
- A technique is a method or procedure used to accomplish a task. It refers to simple problem. For example: a technique used to open the lid of an air tight box.
- A method is a systematic approach to solving a problem. It is more related to creativity and refers to larger problem. For example, method of cracking an IAS exam.
- A process is a series of steps or actions taken to achieve a desired result. For example the process of hiring.

# What is the difference between statistics and census?
Statistics is the science of collecting, organizing, analyzing, and interpreting data. It is about sample data (a portion of the entire population). Census is the process of collecting and counting data about a population. For example, to study economic wellbeing of tribal people if you can collect some sample data then it is part of statistics. But if you collect data of entire tribal population then it is census data.

# Are statistical measures and statistical methods the same?
No, statistical measures and statistical methods are not the same. Statistical measures are the numerical values used to describe data, while statistical methods are the techniques used to analyze data.

# What are the different types of statistics?
The different types of statistics are 
- Descriptive statistics 
- Inferential statistics
- Predictive analytics.

# What is Descriptive statistics?
Descriptive statistics is the process of summarizing and organizing data in order to describe the characteristics of a **population or sample**. It includes measures such as mean, median, mode, range, variance, standard deviation, quartiles, percentiles, skewness, kurtosis, and covariance. There are different ways to calculate these measures.

# Are statistical measures and statistical methods the same?
No, Statistical measures are the **numerical values** used to describe data, while statistical methods are the **techniques** used to analyze data.

# What are statistical measures of Descriptive Statistics?
A: Descriptive statistics measures include mean, median, mode, range, variance, standard deviation, quartiles, percentiles, skewness, kurtosis, and covariance.

# What are statistical measures of inferential Statistics?
Inferential statistics measures include z-score, t-test, chi-square test, correlation coefficient, confidence interval, and p-value.

# What are statistical tool of inferential Statistics?
Regression analysis, hypothesis testing etc.

# What are statistical measures of predictive Statistics?
To measure the performance of statistial models we have several meausre. It depends upon the type of predictor or model type. For example, classification model can be evalauted using precision, recall, accuracy etc. Regression model can be evaluated using R^2 or Adjusted R^2.

# What are statistical tools of predictive Statistics?
Predictive statistics tools are machine learning algorithms, such as linear regresion, logistic regression, decision trees, neural networks, and support vector machines.

# What is a statistical model?
A statistical model is a mathematical representation of a real-world phenomenon. It is used to make predictions and analyze data. The data generated by the model and real-world data will have some difference and this is called error of the model. For example, based on certain parameters like carpet_area, number_of_bedroom etc. a model can predict house price should be 1.2 crore, but actual price is 1 core. Thus model is predicting price as 20 lakhs Rupees more. This is model error. Keeing the people behaviour, market opportunties, etc in mind we can never make a statistical model with zero error. But if could guess the distribution of input variables correctly then output of our model will have lessor errors.





# What is the difference between Statistical Model and Mathematical Model
Mathematical models are deterministic, input is clearly known, outcome is fixed. Newtons's equation of motion is Mathematical Model. It represents the physical reality of the world. In $$s = u*t + \frac{1}{2}*a*t^2$$ You provide the value of u,t and a and you will get accurate s.

Statistical models are non-deterministics or stochastic, some of the inputs are probabilistics, and outcome is probabilistics. When you devlop a model to predict house price then you need statistical model. In your model parameters may be carpet_area, number of bedroom etc. From the sample data we know if area is 2000sft price can be 1cr, it can be 1.2cr or 1.5cr. For the same carepet area price is different. It is not only because of other parameters but because of market opportunties. Thus input, output of the model will be probabiltisics. Because of this non-deterministic nature we need to assume distribution of the data, so that outcome is more certain.

# What is regression?
If you want to predict salary from experience or number of projects you have done then you can use regression analysis.

A generic linear regression equation is $$y=mx+c$$. Where y is dependent variable like salary (which you want to predict), x is independent varialbe like no_of_years_experienct. m is slope of line or coeffcient which will your salary for each unit of experience. c is intercept of line, which will give you value of salary even if experience is zero. For example this model will predict salary in lakhs. $$Salary=2.5*no\_of\_years\_experience+1$$

# What is correlation?
If you want to study the magnitude or direction of relationship between two varialbe you can use this statistical measure.

Regression analysis is a statistical technique used to analyze the relationship between two or more variables.

# What is random variable?
- If you through a dice then outcome can be any number between 1 to 6, inclusive.
- If you check job applicant's age then age can be any number from 18 to 60, knowing this is the age limit.
- If you see traffic movement on a four way cross junction it can be left, right, straight or u-turn.

So variable dice-outcome, applicant-job, traffic-turn-direction can can be any random value between the range or options available. Therefore they are random variable. In database language every table's column is random variable. In statistics this is referred as random variable.

# What are different types of random variables?
A random variable can take any value from the given fix number of options. For example applicant_education applicant_gender, applicant_city, dice_outcome can have fixed number of outcome. This kind of variable is called catgorical variable. Further, there are two types of categorical variable. Applicant_education can be Higher_Secondry, Graduate, Master, Phd. But this random variable has an order from low to high therefore it is called ordinal categorical variable or ordinal variable. Applicant_city or color of the side of dice does not have any order therefore they are called nominal categorical variable or nominal variable.

In this dataset what can be the value of applicant_age or salary? Like earlier, it is not selected from a fixed number of options available. Not only that it can be decimal also. Therefore such kind of random variable is called numeric random variable or numeric variable.
 
# What is success probability?
Let's assume your job_applicant dataset can have applicant only from 6 cities (Mumbai, Delhi, Bangalore, Chennai, Hyderabad, Kolkota). In this dataset you have 10,000 applicant's information. Now if you are interested in only those employees who are from Mumbai, then you can ask question like, what is the probability that a given employee is from Mumbai? In the experiment, if you pickup record number 1008 and this candidate is from Mumbai then you call the event is successful. But, if candidate is from any other city then you call event is fail. Your write it as $$Pr(Applicant\_city=Mumbai)$$.

If this dataset has 2000 candidates from Mumbai then a randomly selected candidate will be from Mumbai, what is the probablity? 2,000/10,000 = .20 or 20% so $$Pr(Applicant\_City=Mumbai)=.20$$. 20% is the success probablity.

Success probability is little tricky in the case of numeric variable. Because if you want to check the probablity of person whose age is 35 years, 3 months, 10 day, 6 hours then question is valid but answer is Probability of success of this event is zero. You pickup any number answer is going to be like that. For example when you say age is 30 years, it means 30 years, 0 month, 0 days, 0 hours. Due to this reason with numeric probalbity you either use >= or <=. It means you can ask a question like, what is the probability of Age of a candidate <=30, or >=30. or >=30 but <=35 years.

In your dataset if you have 3000 people who are <= 30 years then Pr(Applicant_Age<=30) = .30 or 30%.

If your dataset has 5000 people <=35 years then $$Pr(Applicant\_Age<=35) = .50$$  or 50%.

Now you can say Pr(Applicant_age>=30 and <=35) = .50 - .30 = .20 or 20%.

This all is done by exploring another concept called probability density.


# What is probability density?
Let's assume our dataset has 10,000 applicant and their age is between 18 to 60 years. You can plot a histogram and this histogram represents the distribution of age of the applicants. The entire area of this histogram is referred as 1, in our case 10,000 people's age is represented by this area and it is 1. This is the maximum density of this curve. X axis of this curve will have age and y axis will have number of people.

# What is uniform distribution?
Suppose if you age of 100 children in your datasets. And for each age group if number of children are same then it is uniform distribution. 0-5 years 25, 5-10 years 25, 5-15 years 25, and 15-20 years 25 children.

![Uniform Distribution](/assets/images/dspost/statistics/Uniform-Distribution.jpg)

# What is normal distribution? What is the use of this?
Suppose you have age information of 10000 employees of your compnay. Let's the minimum age from this dataset is 20 years (recently hired) there are lessor people like this. Maximum age in the dataset is 60 years (people are going to retire this year), there are lessor people like this. If you plot the histogram of this age information you will get a normal distribution. It means mean and median will be 40 years, 5000 employees are <= 40 years old and 5000 employees are > 40 year age. 

![Normal Distribution](/assets/images/dspost/statistics/Normal-Distribution.jpg)

Ir this age data is truely normally distributed then 68% employees will be within $$\pm 1\sigma$$, 95% employees will be within $$\pm 2\sigma$$, 99% employees will be within $$\pm 3\sigma$$.

![Distribution-Boxplot](/assets/images/dspost/statistics/Distribution-Boxplot.png)
Source: [Wikipedia](https://en.wikipedia.org/wiki/Probability_density_function)

# What is binomial distribution? What is the use of this?
If you throw 2 dice simultaniously then sum of the outcomes can be anything between 2 to 12.

First Dice| 1|2|3|4|5|6
---|---|---|---|---|---|---
**Second Dice**
1 | 2| 3 | 4| 5| 6| 7
2 | 3| 4 | 5| 6| 7| 8
3 | 4| 5 | 6| 7| 8| 9
4 | 5| 6 | 7| 8| 9| 10
5 | 6| 7 | 8| 9| 10|11
6 | 7| 8 | 9| 10| 11|12

There are total 36 ways (above combinations) to get any number between 2 to 12. There is only one way to get 2, 2 ways to get 3, 3 ways to get 4, 4 ways to get 5 etc.

So probality of coming 10 is 3/36, probablity of 7 coming is 6/36 = 1/6, etc. Probability coming 7 is the highest.

If you throw these two dice together 100 times then what is the probablity 20 times 7 will come. To get this answer you need a distribution formula, a distribution which determines this whole game. 

This whole game can be predicted using binomial distribution. Formula is $$pr(suceess=r\, times)= nC_rP^r(1-P)^{n-r}$$, where n= number of times experiment repeated, r=number of times success happens, p=probablity a sucess happens.
Probablity of success means probablity of getting 7. for p=1/6.
$$pr(suceess=20 \,times)= 100C_{20}\frac{1}{6}^{20}(1-\frac{1}{6})^{100-20} =  0.0678$$

We can use binomial distribution for any experiments where outcome is either success or fail (binary) and experiments n times and we want to know the success for r times.

**Application:** You are tracking stock price for TCS share since last 500 days. You want to know that in next 100 days probablity of stock price will cross Rs 800, 10 times. 

You can get P value, the probablity of success from 500 days data. Let's say it has crossed 800, 40 times. P=40/800 = .05. 

$$pr(suceess=10 \,times)= 100C_{10}\frac{1}{.05}^{10}(1-.95)^{100-10} =  .0.0167$$



![Dice Histogram](/assets/images/dspost/statistics/diceHistogram.jpg)


# Explain dependent variables and independent variable.
In regression of classification problem we want to predict or forecast something. It may be house-price, cost-of-project, time-to-complete-project, salary-of-new-hired, promotion of employee, churn-of-a-customer etc. These are called dependent variable. But to predict these we need the help of some other variables, on which the value of these dependent variable depends. Like house-price can be predicted from area of house, cost-of-project can predicted from cost of the materials used etc. These predictors are called independent variables. If there is only one predictor then we need simple linear regression. But in real business or personal life you need more than one predictors, in that situation multi-linear regression is needed to predict.


## What is R-Square formula?
R-Square or $R^2$ is also called coefficient of determination. It is used to evaluate the performance of regression model. $R^2$ value can be any number between 0 and 1 including 0 and 1. If $R^2$ of a model is .80 then it means this model explain 80% variation between actual and predicted values but 20% variation cannot be explained. Higher the $R^2$ value means more variation can be explained by the model and better the model is.

$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$$

Where SSres is the sum of squared residuals (the difference between the predicted value and the actual value) and SStot is the total sum of squares (the difference between the actual value and the mean of all actual values).

----

## What is Adjusted R-Square formula?
$$Adjusted R^2 = 1 - (1 - R^2) * \frac{(n - 1)}{(n - p - 1)}$$

----
## What is Variance Formula?
Variance is a measure of the dispersion of a single set of data. It is calculated as the **sum of the squared differences between each data point and the mean of the data**, divided by the number of data points.

$$\sigma^2 = \frac{\sum_{i=1}^{n} (x_i - \mu)^2}{n}$$


----

## What is Covariance Formula?

It is calculated as the **sum of the products of the differences between each data point in one set and the mean of that set**, and the **differences between the corresponding data points in the other set and the mean of that set**, divided by the number of data points.

$$cov(X, Y) = \frac{\sum_{i=1}^{n} (x_i - \mu_X)(y_i - \mu_Y)}{n}$$

----

## What is AutoCovariance Function (ACVF) Formula?

$$\gamma(k) = Cov(X_t, X_{t+k})$$

----

## What is formula for the Standard Deviation?

**The formula for the sample standard deviation, denoted by "s," is:**
$$s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2}$$

where x is the set of observations, n is the number of observations, and $\bar{x}$ is the mean of the observations.

**The formula for the population standard deviation, denoted by "σ," is:**

$$σ = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_i - \mu)^2}$$

where x is the set of observations, n is the number of observations, and $\mu$ is the mean of the observations.

----

## What is correlation formula?
The formula for Pearson's correlation coefficient, denoted by "r," is:

$$r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2} \sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$

you can also right it like 

$$r = \frac{ \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{n} }

{\sqrt{ \frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})^2} 

\sqrt{ \frac{1}{n} \sum_{i=1}^{n}(y_i - \bar{y})^2}{n} }$$

or

$$ \rho_{(x,y)} = \frac { Cov(x, y)} {(Std(x) * Std(y)) }$$

where x and y are the two variables being correlated, n is the number of observations, and $\bar{x}$ and $\bar{y}$ are the means of the x and y variables, respectively.

----

## How many types of correlation coeffienct are there in stats?

There are several types of correlation coefficients that are commonly used in statistics to measure the **strength** and **direction of a linear relationship** between two variables. Here are a few of the most common ones:

1. Pearson correlation coefficient: The Pearson correlation coefficient is a measure of the linear relationship between two variables. It ranges from -1 to 1, where -1 indicates a strong negative relationship, 0 indicates no relationship, and 1 indicates a strong positive relationship.

2. Spearman rank correlation coefficient: The Spearman rank correlation coefficient is a nonparametric measure of the strength of the monotonic relationship between two variables. It is calculated based on the ranks of the values rather than the raw data.

3. Kendall rank correlation coefficient: The Kendall rank correlation coefficient is another nonparametric measure of the strength of the monotonic relationship between two variables. It is calculated based on the number of concordant and discordant pairs in the data.

4. Partial correlation coefficient: The partial correlation coefficient is a measure of the correlation between two variables, taking into account the influence of one or more additional variables.

5. Intraclass correlation coefficient: The intraclass correlation coefficient is a measure of the degree of agreement between observations that are made on the same subjects. It is commonly used in the analysis of repeated measures data.

It's important to choose the appropriate correlation coefficient based on the nature of the data and the type of relationship you are interested in.

----

## What is concordant or discordant pairs?

Concordant pairs are two variables that tend to increase or decrease together. Discordant pairs, on the other hand, are two variables that tend to move in opposite directions. For example, a positive correlation between the number of hours studied and exam scores would be an example of a concordant pair, while a negative correlation between the number of hours studied and the number of hours spent playing video games would be an example of a discordant pair.

----

## What is monotonic relationship?

A monotonic relationship is a statistical relationship between two variables in which one variable either increases or decreases consistently as the other variable increases. In other words, there is a clear direction to the relationship, but **the relationship may not necessarily be linear**.

For example, consider the relationship between temperature and ice cream sales. As temperature increases, ice cream sales are likely to increase as well. This is a positive monotonic relationship, because one variable (temperature) increases consistently as the other variable (ice cream sales) increases. On the other hand, if temperature were to decrease as ice cream sales increased, the relationship would be **negative monotonic**.

Monotonic relationships can be measured using **nonparametric statistical techniques**, such as the **Spearman rank correlation coefficient** or the **Kendall rank correlation coefficient**. These techniques are based on the ranks of the values rather than the raw data, and they are less sensitive to deviations from a linear relationship than parametric techniques such as the Pearson correlation coefficient.

----

## What is the difference between nonparametric measure vs parametric measure?

Parametric measures are statistical techniques that make assumptions about the underlying distribution of the data. These assumptions are usually about the shape of the distribution and the presence of certain statistical properties, such as a normal distribution or constant variance. Let's say we have a dataset which contains [Paleontology](https://en.wikipedia.org/wiki/Paleontology)  information about various objects. It has one column called age of the object. Can you assume the age column will have normal distribution? I think no. But if we were having an employee dataset and age is mentioned there then you can assume that age will have normal distriubtion. 

Nonparametric measures, on the other hand, do not make any assumptions about the underlying distribution of the data. They are more flexible and can be used with a wider range of data types, but they may be less powerful than parametric measures because they make fewer assumptions about the data.

One of the main differences between parametric and nonparametric measures is the way they handle missing data. Parametric measures typically require complete data sets, while nonparametric measures are more robust to missing data.

It's important to choose the appropriate statistical technique based on the nature of the data and the research question you are trying to answer. In general, parametric measures are more powerful when the assumptions they make about the data are met, but nonparametric measures may be more appropriate when these assumptions are not met.

----