---
id: 6006    
title: "Confusion Matrix Bayesian Theorem"
date: '2022-07-22T15:50:00+05:30'
permalink: /dsblog/Confusion-Matrix-Bayesian-Theorem
categories:
  - Blog
tags:
  - Confusion Matrix
  - Precision
  - Recall
  - F1 Score
  - Sensitivity
  - Error Rate
header:
  teaser: "/assets/images/dspost/dsp6006-Confusion-Matrix-Bayesian-Theorem.jpg"
excerpt_separator: "<!--more-->"
excerpt:
layout: single
author_profile: true
---

![Confusion Matrix](/assets/images/dspost/dsp6006-Confusion-Matrix-Bayesian-Theorem.jpg)   

If you are like me then you must have struggled enough to understand the confusion matrix or still struggling to understand the metrics of this confusion matrix. A simple 2Ã—2 actual vs predicted values matrix can be looked at and analyzed from different angles and hence we can have all different metrics from this. The beauty of all these metrics is different metrics are important for evaluating different kinds of models.

Before starting to evaluate a model performance an ML engineer must establish metrics that he/she want to use to evaluate the model. Hence it becomes extremely critical for an ML engineer to understand what are the different metrics and what is the meaning of each of those metrics. In this presentation, I am putting all the metrics at one page with example and numbers so that it is easier for your to visualize the big picture.

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vROmlLQEfDo9x7LZDAoazEzRJOqnQ9oKshR_rfXFPqlIom3jIPJAvButKOPuO_G0_FjMWARR5knkdpK/embed?start=false&loop=false&delayms=3000" frameborder="0" width="650" height="350" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

