---
mathjax: true
id: 6088
title: Paper-Summary: A Survey Paper# Pretrained Language Models for Text Generation
date: 2023-08-18
permalink: '/dsblog/what-is-llm'
tags: [AI Paper, NLP, Pretrained Model]
categories:

header:
    teaser: /assets/images/dspost/dsp6088-Pretrained-Language-Models-for-Text-Generation.jpg
excerpt_separator: "<!--more-->"  
excerpt:  
layout: single  
author_profile: true  
toc: True  
toc_sticky: true
---

![Pretrained Language Models for Text Generation]( /assets/images/dspost/dsp6088-Pretrained-Language-Models-for-Text-Generation.jpg)

  
**Paper Name:- Pretrained Language Models for Text Generation: A Survey**  
Typer of Paper:- Survey Paper     
[Paper URL](https://arxiv.org/abs/2105.10311)    

# Paper Summary:- Pretrained Language Models for Text Generation

## Key Ideas from the Paper

- This paper discusses "major advances achieved in the topic of PLMs for text generation"
- This survey aims to provide "text generation researchers a synthesis" and pointer to related research.
- Text generation has become one of the most important yet challenging tasks in natural language processing (NLP). 
- Neural generation model are deep learning models
- Pretrained language models (PLMs) are neural generation model

## Paper Outcome
- General task deﬁnition
- Describe the mainstream architectures of PLMs for text generation. 
- How to adapt existing PLMs to model different input data and satisfy special properties in the generated text. 
- Summarize several important ﬁne-tuning strategies for text generation. 

